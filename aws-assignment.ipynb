{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers \"datasets[s3]==2.18.0\" \"sagemaker>=2.190.0\" \"huggingface_hub[cli]\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token YOUR_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name philippschmid to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::558105141721:role/sagemaker_execution_role\n",
      "sagemaker bucket: sagemaker-us-east-1-558105141721\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94076a5d900c4217be5c8613b6f762d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\nCREATE TABLE table_name_33 (make VARCHAR, pos INTEGER)', 'role': 'system'}, {'content': 'Which Make has a Pos larger than 9?', 'role': 'user'}, {'content': 'SELECT make FROM table_name_33 WHERE pos > 9', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Convert dataset to OAI messages\n",
    "system_message = \"\"\"You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\n",
    "SCHEMA:\n",
    "{schema}\"\"\"\n",
    "\n",
    "def create_conversation(sample):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message.format(schema=sample[\"context\"])},\n",
    "      {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "      {\"role\": \"assistant\", \"content\": sample[\"answer\"]}\n",
    "    ]\n",
    "  }\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\n",
    "dataset = dataset.shuffle().select(range(12500))\n",
    "\n",
    "# Convert dataset to OAI messages\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features,batched=False)\n",
    "# split dataset into 10,000 training samples and 2,500 test samples\n",
    "dataset = dataset.train_test_split(test_size=2500/12500)\n",
    "\n",
    "print(dataset[\"train\"][345][\"messages\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we processed the datasets we are going to use the [FileSystem integration](https://huggingface.co/docs/datasets/filesystems) to upload our dataset to S3. We are using the `sess.default_bucket()`, adjust this if you want to store the dataset in a different S3 bucket. We will use the S3 path later in our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dev/lib/python3.9/site-packages/fsspec/registry.py:272: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2c0ce52e1d4efea85243e1e0de889b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f5cd3fcdfc46bfbbf9eeee4e5316c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to:\n",
      "s3://sagemaker-us-east-1-558105141721/datasets/text-to-sql/train_dataset.json\n",
      "https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-558105141721/?region=us-east-1&prefix=datasets/text-to-sql/\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3 using our SageMaker session\n",
    "training_input_path = f's3://{sess.default_bucket()}/datasets/text-to-sql'\n",
    "\n",
    "# save datasets to s3\n",
    "dataset[\"train\"].to_json(f\"{training_input_path}/train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(f\"{training_input_path}/test_dataset.json\", orient=\"records\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(f\"{training_input_path}/train_dataset.json\")\n",
    "print(f\"https://s3.console.aws.amazon.com/s3/buckets/{sess.default_bucket()}/?region={sess.boto_region_name}&prefix={training_input_path.split('/', 3)[-1]}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {\n",
    "  ### SCRIPT PARAMETERS ###\n",
    "  'dataset_path': '/opt/ml/input/data/training/train_dataset.json', # path where sagemaker will save training dataset\n",
    "  'model_id': \"codellama/CodeLlama-7b-hf\",           # or `mistralai/Mistral-7B-v0.1`\n",
    "  'max_seq_len': 3072,                               # max sequence length for model and packing of the dataset\n",
    "  'use_qlora': True,                                 # use QLoRA model\n",
    "  ### TRAINING PARAMETERS ###\n",
    "  'num_train_epochs': 3,                             # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                  # batch size per device during training\n",
    "  'gradient_accumulation_steps': 4,                  # number of steps before performing a backward/update pass\n",
    "  'gradient_checkpointing': True,                    # use gradient checkpointing to save memory\n",
    "  'optim': \"adamw_torch_fused\",                      # use fused adamw optimizer\n",
    "  'logging_steps': 10,                               # log every 10 steps\n",
    "  'save_strategy': \"epoch\",                          # save checkpoint every epoch\n",
    "  'learning_rate': 2e-4,                             # learning rate, based on QLoRA paper\n",
    "  'bf16': True,                                      # use bfloat16 precision\n",
    "  'tf32': True,                                      # use tf32 precision\n",
    "  'max_grad_norm': 0.3,                              # max gradient norm based on QLoRA paper\n",
    "  'warmup_ratio': 0.03,                              # warmup ratio based on QLoRA paper\n",
    "  'lr_scheduler_type': \"constant\",                   # use constant learning rate scheduler\n",
    "  'report_to': \"tensorboard\",                        # report metrics to tensorboard\n",
    "  'output_dir': '/tmp/tun',                          # Temporary output directory for model checkpoints\n",
    "  'merge_adapters': True,                            # merge LoRA adapters into model for easier deployment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f'codellama-7b-hf-text-to-sql-exp1'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_sft.py',    # train script\n",
    "    source_dir           = '../scripts/trl',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.2xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    disable_output_compression = True,        # not compress output to save training time and cost\n",
    "    environment          = {\n",
    "                            \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\", # set env variable to cache models in /tmp\n",
    "                            \"HF_TOKEN\": \"token\" # huggingface token to access gated models, e.g. llama 2\n",
    "                            }, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: codellama-7b-hf-text-to-sql-exp1-2024-03-08-08-05-53-957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-08 08:05:55 Starting - Starting the training job\n",
      "2024-03-08 08:05:55 Pending - Training job waiting for capacity......\n",
      "2024-03-08 08:06:33 Pending - Preparing the instances for training...\n",
      "2024-03-08 08:07:15 Downloading - Downloading input data...\n",
      "2024-03-08 08:07:34 Downloading - Downloading the training image...............\n",
      "2024-03-08 08:10:25 Training - Training image download completed. Training in progress.....bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-03-08 08:11:01,570 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-03-08 08:11:01,588 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-08 08:11:01,598 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-03-08 08:11:01,600 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-03-08 08:11:03,036 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.10 -m pip install -r requirements.txt\n",
      "Collecting transformers==4.38.2 (from -r requirements.txt (line 1))\n",
      "Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.7/130.7 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting datasets==2.18.0 (from -r requirements.txt (line 2))\n",
      "Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate==0.27.2 (from -r requirements.txt (line 3))\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: evaluate==0.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: bitsandbytes==0.42.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.42.0)\n",
      "Collecting trl==0.7.11 (from -r requirements.txt (line 6))\n",
      "Downloading trl-0.7.11-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting peft==0.8.2 (from -r requirements.txt (line 7))\n",
      "Downloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting flash-attn==2.5.6 (from -r requirements.txt (line 8))\n",
      "Downloading flash_attn-2.5.6.tar.gz (2.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 62.3 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (2.1.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->-r requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.9.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2->-r requirements.txt (line 3)) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1->-r requirements.txt (line 4)) (0.18.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 5)) (1.11.3)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.11->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.6->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.6->-r requirements.txt (line 8)) (1.11.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (0.15)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (13.6.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (1.6.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (0.1.0)\n",
      "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 112.2 MB/s eta 0:00:00\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.5/510.5 kB 58.0 MB/s eta 0:00:00\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.0/280.0 kB 43.2 MB/s eta 0:00:00\n",
      "Downloading trl-0.7.11-py3-none-any.whl (155 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 27.7 MB/s eta 0:00:00\n",
      "Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 183.4/183.4 kB 31.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: flash-attn\n",
      "Building wheel for flash-attn (setup.py): started\n",
      "Building wheel for flash-attn (setup.py): finished with status 'done'\n",
      "Created wheel for flash-attn: filename=flash_attn-2.5.6-cp310-cp310-linux_x86_64.whl size=120352136 sha256=63ab5a3883b67719671e154beb91522e2901cbe4af0c5e031306a06a85df0be5\n",
      "Stored in directory: /root/.cache/pip/wheels/a8/1c/88/b959d6818b98a46d61ba231683abb7523b89ac1a7ed1e0c206\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: flash-attn, accelerate, transformers, datasets, trl, peft\n",
      "Attempting uninstall: flash-attn\n",
      "Found existing installation: flash-attn 2.3.6\n",
      "Uninstalling flash-attn-2.3.6:\n",
      "Successfully uninstalled flash-attn-2.3.6\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.25.0\n",
      "Uninstalling accelerate-0.25.0:\n",
      "Successfully uninstalled accelerate-0.25.0\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.36.0\n",
      "Uninstalling transformers-4.36.0:\n",
      "Successfully uninstalled transformers-4.36.0\n",
      "Attempting uninstall: datasets\n",
      "Found existing installation: datasets 2.15.0\n",
      "Uninstalling datasets-2.15.0:\n",
      "Successfully uninstalled datasets-2.15.0\n",
      "Attempting uninstall: trl\n",
      "Found existing installation: trl 0.7.4\n",
      "Uninstalling trl-0.7.4:\n",
      "Successfully uninstalled trl-0.7.4\n",
      "Attempting uninstall: peft\n",
      "Found existing installation: peft 0.7.1\n",
      "Uninstalling peft-0.7.1:\n",
      "Successfully uninstalled peft-0.7.1\n",
      "Successfully installed accelerate-0.27.2 datasets-2.18.0 flash-attn-2.5.6 peft-0.8.2 transformers-4.38.2 trl-0.7.11\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2024-03-08 08:11:21,714 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-03-08 08:11:21,714 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-03-08 08:11:21,751 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-08 08:11:21,779 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-08 08:11:21,807 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-03-08 08:11:21,819 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training/train_dataset.json\",\n",
      "        \"gradient_accumulation_steps\": 4,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"constant\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"max_seq_len\": 3072,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"codellama/CodeLlama-7b-hf\",\n",
      "        \"num_train_epochs\": 3,\n",
      "        \"optim\": \"adamw_torch_fused\",\n",
      "        \"output_dir\": \"/tmp/tun\",\n",
      "        \"per_device_train_batch_size\": 1,\n",
      "        \"report_to\": \"tensorboard\",\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_qlora\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"codellama-7b-hf-text-to-sql-exp1-2024-03-08-08-05-53-957\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-558105141721/codellama-7b-hf-text-to-sql-exp1-2024-03-08-08-05-53-957/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_sft\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_sft.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training/train_dataset.json\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"constant\",\"max_grad_norm\":0.3,\"max_seq_len\":3072,\"merge_adapters\":true,\"model_id\":\"codellama/CodeLlama-7b-hf\",\"num_train_epochs\":3,\"optim\":\"adamw_torch_fused\",\"output_dir\":\"/tmp/tun\",\"per_device_train_batch_size\":1,\"report_to\":\"tensorboard\",\"save_strategy\":\"epoch\",\"tf32\":true,\"use_qlora\":true,\"warmup_ratio\":0.03}\n",
      "SM_USER_ENTRY_POINT=run_sft.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"training\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=run_sft\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-558105141721/codellama-7b-hf-text-to-sql-exp1-2024-03-08-08-05-53-957/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training/train_dataset.json\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"constant\",\"max_grad_norm\":0.3,\"max_seq_len\":3072,\"merge_adapters\":true,\"model_id\":\"codellama/CodeLlama-7b-hf\",\"num_train_epochs\":3,\"optim\":\"adamw_torch_fused\",\"output_dir\":\"/tmp/tun\",\"per_device_train_batch_size\":1,\"report_to\":\"tensorboard\",\"save_strategy\":\"epoch\",\"tf32\":true,\"use_qlora\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"codellama-7b-hf-text-to-sql-exp1-2024-03-08-08-05-53-957\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-558105141721/codellama-7b-hf-text-to-sql-exp1-2024-03-08-08-05-53-957/source/sourcedir.tar.gz\",\"module_name\":\"run_sft\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_sft.py\"}\n",
      "SM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training/train_dataset.json\",\"--gradient_accumulation_steps\",\"4\",\"--gradient_checkpointing\",\"True\",\"--learning_rate\",\"0.0002\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"constant\",\"--max_grad_norm\",\"0.3\",\"--max_seq_len\",\"3072\",\"--merge_adapters\",\"True\",\"--model_id\",\"codellama/CodeLlama-7b-hf\",\"--num_train_epochs\",\"3\",\"--optim\",\"adamw_torch_fused\",\"--output_dir\",\"/tmp/tun\",\"--per_device_train_batch_size\",\"1\",\"--report_to\",\"tensorboard\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_qlora\",\"True\",\"--warmup_ratio\",\"0.03\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_HP_BF16=true\n",
      "SM_HP_DATASET_PATH=/opt/ml/input/data/training/train_dataset.json\n",
      "SM_HP_GRADIENT_ACCUMULATION_STEPS=4\n",
      "SM_HP_GRADIENT_CHECKPOINTING=true\n",
      "SM_HP_LEARNING_RATE=0.0002\n",
      "SM_HP_LOGGING_STEPS=10\n",
      "SM_HP_LR_SCHEDULER_TYPE=constant\n",
      "SM_HP_MAX_GRAD_NORM=0.3\n",
      "SM_HP_MAX_SEQ_LEN=3072\n",
      "SM_HP_MERGE_ADAPTERS=true\n",
      "SM_HP_MODEL_ID=codellama/CodeLlama-7b-hf\n",
      "SM_HP_NUM_TRAIN_EPOCHS=3\n",
      "SM_HP_OPTIM=adamw_torch_fused\n",
      "SM_HP_OUTPUT_DIR=/tmp/tun\n",
      "SM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=1\n",
      "SM_HP_REPORT_TO=tensorboard\n",
      "SM_HP_SAVE_STRATEGY=epoch\n",
      "SM_HP_TF32=true\n",
      "SM_HP_USE_QLORA=true\n",
      "SM_HP_WARMUP_RATIO=0.03\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.10 run_sft.py --bf16 True --dataset_path /opt/ml/input/data/training/train_dataset.json --gradient_accumulation_steps 4 --gradient_checkpointing True --learning_rate 0.0002 --logging_steps 10 --lr_scheduler_type constant --max_grad_norm 0.3 --max_seq_len 3072 --merge_adapters True --model_id codellama/CodeLlama-7b-hf --num_train_epochs 3 --optim adamw_torch_fused --output_dir /tmp/tun --per_device_train_batch_size 1 --report_to tensorboard --save_strategy epoch --tf32 True --use_qlora True --warmup_ratio 0.03\n",
      "2024-03-08 08:11:21,820 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "2024-03-08 08:11:21,820 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 10000 examples [00:00, 688538.97 examples/s]\n",
      "Using QLoRA\n",
      "config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]\n",
      "config.json: 100%|██████████| 637/637 [00:00<00:00, 7.30MB/s]\n",
      "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\n",
      "model.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 159MB/s]\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]#033[A\n",
      "model-00001-of-00002.safetensors:   1%|          | 62.9M/9.98G [00:00<00:18, 551MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   1%|▏         | 126M/9.98G [00:00<00:20, 487MB/s] #033[A\n",
      "model-00001-of-00002.safetensors:   2%|▏         | 178M/9.98G [00:00<00:20, 474MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   2%|▏         | 231M/9.98G [00:00<00:20, 483MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   3%|▎         | 283M/9.98G [00:00<00:19, 488MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   3%|▎         | 336M/9.98G [00:00<00:19, 488MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   4%|▍         | 388M/9.98G [00:00<00:19, 491MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   5%|▍         | 451M/9.98G [00:00<00:18, 517MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   5%|▌         | 503M/9.98G [00:01<00:18, 508MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   6%|▌         | 556M/9.98G [00:01<00:19, 484MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   6%|▌         | 608M/9.98G [00:01<00:19, 471MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   7%|▋         | 661M/9.98G [00:01<00:20, 458MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   7%|▋         | 713M/9.98G [00:01<00:20, 463MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   8%|▊         | 765M/9.98G [00:01<00:20, 454MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   8%|▊         | 818M/9.98G [00:01<00:20, 442MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   9%|▊         | 870M/9.98G [00:01<00:20, 454MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:   9%|▉         | 923M/9.98G [00:01<00:20, 449MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  10%|▉         | 975M/9.98G [00:02<00:19, 460MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  10%|█         | 1.03G/9.98G [00:02<00:19, 451MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  11%|█         | 1.08G/9.98G [00:02<00:20, 430MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  11%|█▏        | 1.13G/9.98G [00:02<00:20, 438MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  12%|█▏        | 1.18G/9.98G [00:02<00:19, 441MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  12%|█▏        | 1.24G/9.98G [00:02<00:19, 443MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  13%|█▎        | 1.29G/9.98G [00:02<00:19, 444MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  13%|█▎        | 1.34G/9.98G [00:02<00:18, 458MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  14%|█▍        | 1.39G/9.98G [00:03<00:19, 442MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  15%|█▍        | 1.45G/9.98G [00:03<00:18, 454MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  15%|█▌        | 1.50G/9.98G [00:03<00:18, 466MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  16%|█▌        | 1.55G/9.98G [00:03<00:19, 440MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  16%|█▌        | 1.60G/9.98G [00:03<00:18, 447MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  17%|█▋        | 1.66G/9.98G [00:03<00:19, 425MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  17%|█▋        | 1.72G/9.98G [00:03<00:17, 463MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  18%|█▊        | 1.77G/9.98G [00:03<00:18, 456MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  18%|█▊        | 1.82G/9.98G [00:03<00:18, 432MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  19%|█▉        | 1.88G/9.98G [00:04<00:18, 444MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  19%|█▉        | 1.93G/9.98G [00:04<00:17, 456MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  20%|█▉        | 1.98G/9.98G [00:04<00:17, 450MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  20%|██        | 2.03G/9.98G [00:04<00:17, 463MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  21%|██        | 2.09G/9.98G [00:04<00:17, 457MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  21%|██▏       | 2.14G/9.98G [00:04<00:17, 447MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  22%|██▏       | 2.19G/9.98G [00:04<00:17, 440MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  22%|██▏       | 2.24G/9.98G [00:04<00:16, 455MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  23%|██▎       | 2.30G/9.98G [00:05<00:16, 467MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  24%|██▎       | 2.35G/9.98G [00:05<00:16, 465MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  24%|██▍       | 2.40G/9.98G [00:05<00:16, 454MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  25%|██▍       | 2.45G/9.98G [00:05<00:16, 449MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  25%|██▌       | 2.51G/9.98G [00:05<00:15, 469MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  26%|██▌       | 2.56G/9.98G [00:05<00:15, 471MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  26%|██▌       | 2.61G/9.98G [00:05<00:15, 461MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  27%|██▋       | 2.66G/9.98G [00:05<00:16, 452MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  27%|██▋       | 2.73G/9.98G [00:05<00:15, 470MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  28%|██▊       | 2.78G/9.98G [00:06<00:15, 459MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  28%|██▊       | 2.83G/9.98G [00:06<00:15, 469MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  29%|██▉       | 2.88G/9.98G [00:06<00:14, 473MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  29%|██▉       | 2.94G/9.98G [00:06<00:15, 465MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  30%|██▉       | 2.99G/9.98G [00:06<00:14, 476MB/s]\n",
      "#033[A\n",
      "model-00001-of-00002.safetensors:  30%|███       | 3.04G/9.98G [00:06<00:14, 479MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  31%|███       | 3.09G/9.98G [00:06<00:14, 465MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  32%|███▏      | 3.15G/9.98G [00:06<00:14, 471MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  32%|███▏      | 3.20G/9.98G [00:06<00:14, 460MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  33%|███▎      | 3.25G/9.98G [00:07<00:14, 469MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  33%|███▎      | 3.30G/9.98G [00:07<00:14, 470MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  34%|███▎      | 3.36G/9.98G [00:07<00:14, 459MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  34%|███▍      | 3.41G/9.98G [00:07<00:13, 470MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  35%|███▍      | 3.46G/9.98G [00:07<00:13, 472MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  35%|███▌      | 3.52G/9.98G [00:07<00:13, 495MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  36%|███▌      | 3.58G/9.98G [00:07<00:13, 476MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  36%|███▋      | 3.63G/9.98G [00:07<00:13, 487MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  37%|███▋      | 3.69G/9.98G [00:07<00:12, 507MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  38%|███▊      | 3.74G/9.98G [00:08<00:12, 483MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  38%|███▊      | 3.80G/9.98G [00:08<00:12, 487MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  39%|███▊      | 3.86G/9.98G [00:08<00:12, 499MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  39%|███▉      | 3.91G/9.98G [00:08<00:12, 495MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  40%|███▉      | 3.96G/9.98G [00:08<00:12, 477MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  40%|████      | 4.02G/9.98G [00:08<00:12, 489MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  41%|████      | 4.07G/9.98G [00:08<00:12, 489MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  41%|████▏     | 4.12G/9.98G [00:08<00:11, 495MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  42%|████▏     | 4.17G/9.98G [00:08<00:12, 475MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  42%|████▏     | 4.23G/9.98G [00:09<00:12, 466MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  43%|████▎     | 4.28G/9.98G [00:09<00:12, 467MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  44%|████▎     | 4.34G/9.98G [00:09<00:11, 482MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  44%|████▍     | 4.39G/9.98G [00:09<00:11, 487MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  45%|████▍     | 4.46G/9.98G [00:09<00:10, 507MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  45%|████▌     | 4.52G/9.98G [00:09<00:10, 514MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  46%|████▌     | 4.58G/9.98G [00:09<00:10, 499MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  46%|████▋     | 4.63G/9.98G [00:09<00:10, 501MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  47%|████▋     | 4.69G/9.98G [00:09<00:10, 501MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  48%|████▊     | 4.74G/9.98G [00:10<00:11, 474MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  48%|████▊     | 4.79G/9.98G [00:10<00:10, 485MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  49%|████▊     | 4.84G/9.98G [00:10<00:10, 481MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  49%|████▉     | 4.90G/9.98G [00:10<00:11, 438MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  50%|████▉     | 4.95G/9.98G [00:10<00:11, 448MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  50%|█████     | 5.00G/9.98G [00:10<00:10, 459MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  51%|█████     | 5.05G/9.98G [00:10<00:12, 387MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  51%|█████▏    | 5.12G/9.98G [00:10<00:11, 434MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  52%|█████▏    | 5.17G/9.98G [00:11<00:10, 450MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  52%|█████▏    | 5.22G/9.98G [00:11<00:10, 465MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  53%|█████▎    | 5.27G/9.98G [00:11<00:10, 470MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  53%|█████▎    | 5.33G/9.98G [00:11<00:09, 471MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  54%|█████▍    | 5.38G/9.98G [00:11<00:09, 475MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  54%|█████▍    | 5.43G/9.98G [00:11<00:09, 471MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  55%|█████▍    | 5.48G/9.98G [00:11<00:09, 463MB/s]\n",
      "#033[A\n",
      "model-00001-of-00002.safetensors:  55%|█████▌    | 5.54G/9.98G [00:11<00:09, 469MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  56%|█████▌    | 5.59G/9.98G [00:12<00:11, 397MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  56%|█████▋    | 5.63G/9.98G [00:12<00:11, 378MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  57%|█████▋    | 5.68G/9.98G [00:12<00:10, 392MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  57%|█████▋    | 5.73G/9.98G [00:12<00:13, 311MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  58%|█████▊    | 5.77G/9.98G [00:12<00:13, 323MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  58%|█████▊    | 5.82G/9.98G [00:12<00:12, 339MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  59%|█████▉    | 5.86G/9.98G [00:12<00:14, 282MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  59%|█████▉    | 5.91G/9.98G [00:13<00:12, 329MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  60%|█████▉    | 5.96G/9.98G [00:13<00:18, 214MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  60%|██████    | 6.02G/9.98G [00:13<00:14, 271MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  61%|██████    | 6.08G/9.98G [00:13<00:11, 328MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  61%|██████▏   | 6.12G/9.98G [00:13<00:12, 307MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  62%|██████▏   | 6.17G/9.98G [00:13<00:11, 328MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  62%|██████▏   | 6.21G/9.98G [00:14<00:11, 326MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  63%|██████▎   | 6.25G/9.98G [00:14<00:14, 255MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  63%|██████▎   | 6.28G/9.98G [00:14<00:16, 225MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  63%|██████▎   | 6.31G/9.98G [00:14<00:18, 203MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  64%|██████▎   | 6.34G/9.98G [00:14<00:19, 191MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  64%|██████▍   | 6.36G/9.98G [00:15<00:20, 180MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  64%|██████▍   | 6.39G/9.98G [00:15<00:19, 183MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  64%|██████▍   | 6.41G/9.98G [00:15<00:19, 179MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  64%|██████▍   | 6.43G/9.98G [00:15<00:20, 169MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  65%|██████▍   | 6.46G/9.98G [00:15<00:19, 182MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  65%|██████▍   | 6.48G/9.98G [00:15<00:18, 187MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  65%|██████▌   | 6.51G/9.98G [00:15<00:18, 183MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  66%|██████▌   | 6.54G/9.98G [00:16<00:17, 199MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  66%|██████▌   | 6.57G/9.98G [00:16<00:16, 202MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  66%|██████▌   | 6.60G/9.98G [00:16<00:16, 202MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  66%|██████▋   | 6.63G/9.98G [00:16<00:16, 201MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  67%|██████▋   | 6.66G/9.98G [00:16<00:15, 209MB/s]\n",
      "#033[A\n",
      "model-00001-of-00002.safetensors:  67%|██████▋   | 6.69G/9.98G [00:16<00:16, 204MB/s]\n",
      "#033[A\n",
      "model-00001-of-00002.safetensors:  67%|██████▋   | 6.72G/9.98G [00:16<00:15, 208MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  68%|██████▊   | 6.74G/9.98G [00:16<00:15, 204MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  68%|██████▊   | 6.77G/9.98G [00:17<00:15, 207MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  68%|██████▊   | 6.79G/9.98G [00:17<00:15, 204MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  68%|██████▊   | 6.83G/9.98G [00:17<00:15, 201MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  69%|██████▊   | 6.86G/9.98G [00:17<00:15, 206MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  69%|██████▉   | 6.89G/9.98G [00:17<00:15, 204MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  69%|██████▉   | 6.92G/9.98G [00:17<00:14, 207MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  70%|██████▉   | 6.94G/9.98G [00:17<00:14, 206MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  70%|██████▉   | 6.97G/9.98G [00:18<00:14, 204MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  70%|███████   | 7.00G/9.98G [00:18<00:14, 204MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  71%|███████   | 7.04G/9.98G [00:18<00:14, 208MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  71%|███████   | 7.06G/9.98G [00:18<00:14, 208MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  71%|███████   | 7.08G/9.98G [00:18<00:14, 205MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  71%|███████▏  | 7.11G/9.98G [00:18<00:13, 208MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  71%|███████▏  | 7.13G/9.98G [00:18<00:13, 204MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  72%|███████▏  | 7.16G/9.98G [00:19<00:13, 206MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  72%|███████▏  | 7.18G/9.98G [00:19<00:13, 204MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  72%|███████▏  | 7.21G/9.98G [00:19<00:13, 208MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  73%|███████▎  | 7.24G/9.98G [00:19<00:13, 203MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  73%|███████▎  | 7.27G/9.98G [00:19<00:13, 207MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  73%|███████▎  | 7.29G/9.98G [00:19<00:13, 203MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  73%|███████▎  | 7.32G/9.98G [00:19<00:12, 207MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  74%|███████▎  | 7.34G/9.98G [00:19<00:12, 203MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  74%|███████▍  | 7.36G/9.98G [00:20<00:12, 204MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  74%|███████▍  | 7.39G/9.98G [00:20<00:12, 207MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  74%|███████▍  | 7.41G/9.98G [00:20<00:12, 207MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  75%|███████▍  | 7.44G/9.98G [00:20<00:12, 209MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  75%|███████▍  | 7.47G/9.98G [00:20<00:12, 209MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  75%|███████▌  | 7.49G/9.98G [00:20<00:12, 200MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  75%|███████▌  | 7.52G/9.98G [00:20<00:11, 206MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  76%|███████▌  | 7.54G/9.98G [00:20<00:12, 201MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  76%|███████▌  | 7.57G/9.98G [00:21<00:11, 205MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  76%|███████▌  | 7.60G/9.98G [00:21<00:11, 202MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  77%|███████▋  | 7.63G/9.98G [00:21<00:11, 208MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  77%|███████▋  | 7.67G/9.98G [00:21<00:11, 207MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  77%|███████▋  | 7.70G/9.98G [00:21<00:10, 209MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  77%|███████▋  | 7.72G/9.98G [00:21<00:11, 202MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 7.75G/9.98G [00:21<00:10, 206MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 7.77G/9.98G [00:22<00:11, 200MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 7.79G/9.98G [00:22<00:10, 199MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 7.81G/9.98G [00:22<00:10, 200MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  79%|███████▊  | 7.83G/9.98G [00:22<00:11, 195MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  79%|███████▊  | 7.85G/9.98G [00:22<00:11, 189MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  79%|███████▉  | 7.87G/9.98G [00:22<00:10, 194MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  79%|███████▉  | 7.90G/9.98G [00:22<00:10, 192MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  79%|███████▉  | 7.92G/9.98G [00:22<00:11, 187MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  80%|███████▉  | 7.94G/9.98G [00:22<00:10, 187MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  80%|███████▉  | 7.96G/9.98G [00:23<00:11, 183MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  80%|███████▉  | 7.98G/9.98G [00:23<00:10, 188MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  80%|████████  | 8.00G/9.98G [00:23<00:10, 182MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  80%|████████  | 8.02G/9.98G [00:23<00:10, 188MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  81%|████████  | 8.04G/9.98G [00:23<00:16, 120MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  81%|████████  | 8.11G/9.98G [00:23<00:08, 210MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 8.14G/9.98G [00:23<00:09, 199MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 8.17G/9.98G [00:24<00:09, 194MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 8.20G/9.98G [00:24<00:09, 191MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 8.22G/9.98G [00:24<00:09, 190MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 8.24G/9.98G [00:24<00:09, 188MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 8.26G/9.98G [00:24<00:08, 192MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 8.28G/9.98G [00:24<00:09, 187MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 8.30G/9.98G [00:24<00:08, 187MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 8.33G/9.98G [00:24<00:08, 185MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  84%|████████▎ | 8.35G/9.98G [00:25<00:08, 185MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  84%|████████▍ | 8.37G/9.98G [00:25<00:08, 183MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  84%|████████▍ | 8.39G/9.98G [00:25<00:08, 184MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  84%|████████▍ | 8.41G/9.98G [00:25<00:08, 178MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  85%|████████▍ | 8.43G/9.98G [00:25<00:08, 178MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  85%|████████▍ | 8.45G/9.98G [00:25<00:08, 182MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  85%|████████▍ | 8.47G/9.98G [00:25<00:08, 172MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  85%|████████▌ | 8.49G/9.98G [00:25<00:08, 181MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  85%|████████▌ | 8.51G/9.98G [00:26<00:08, 179MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  86%|████████▌ | 8.54G/9.98G [00:26<00:07, 185MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  86%|████████▌ | 8.56G/9.98G [00:26<00:08, 176MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  86%|████████▌ | 8.58G/9.98G [00:26<00:07, 176MB/s]\n",
      "#033[A\n",
      "model-00001-of-00002.safetensors:  86%|████████▌ | 8.60G/9.98G [00:26<00:08, 171MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  86%|████████▋ | 8.62G/9.98G [00:26<00:07, 173MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  87%|████████▋ | 8.65G/9.98G [00:26<00:07, 179MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  87%|████████▋ | 8.67G/9.98G [00:26<00:07, 179MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  87%|████████▋ | 8.69G/9.98G [00:27<00:07, 183MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  87%|████████▋ | 8.71G/9.98G [00:27<00:06, 183MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 8.73G/9.98G [00:27<00:06, 184MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 8.76G/9.98G [00:27<00:06, 179MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 8.78G/9.98G [00:27<00:06, 180MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 8.80G/9.98G [00:27<00:06, 172MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 8.82G/9.98G [00:27<00:06, 178MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  89%|████████▊ | 8.84G/9.98G [00:27<00:06, 180MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  89%|████████▉ | 8.86G/9.98G [00:27<00:06, 179MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  89%|████████▉ | 8.88G/9.98G [00:28<00:06, 176MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  89%|████████▉ | 8.90G/9.98G [00:28<00:06, 173MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  89%|████████▉ | 8.92G/9.98G [00:28<00:06, 173MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  90%|████████▉ | 8.94G/9.98G [00:28<00:06, 168MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  90%|████████▉ | 8.97G/9.98G [00:28<00:05, 175MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  90%|█████████ | 8.99G/9.98G [00:28<00:05, 171MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  90%|█████████ | 9.01G/9.98G [00:28<00:05, 168MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  90%|█████████ | 9.03G/9.98G [00:28<00:05, 168MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  91%|█████████ | 9.05G/9.98G [00:29<00:05, 164MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  91%|█████████ | 9.08G/9.98G [00:29<00:05, 175MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  91%|█████████ | 9.10G/9.98G [00:29<00:05, 172MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  91%|█████████▏| 9.12G/9.98G [00:29<00:04, 174MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 9.14G/9.98G [00:29<00:04, 171MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 9.16G/9.98G [00:29<00:04, 168MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 9.19G/9.98G [00:29<00:04, 173MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 9.21G/9.98G [00:30<00:04, 168MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 9.23G/9.98G [00:30<00:04, 171MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████▎| 9.25G/9.98G [00:30<00:04, 178MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████▎| 9.27G/9.98G [00:30<00:04, 172MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████▎| 9.29G/9.98G [00:30<00:03, 180MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████▎| 9.31G/9.98G [00:30<00:03, 172MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  94%|█████████▎| 9.33G/9.98G [00:30<00:03, 165MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  94%|█████████▍| 9.35G/9.98G [00:30<00:03, 168MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  94%|█████████▍| 9.38G/9.98G [00:31<00:03, 175MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  94%|█████████▍| 9.41G/9.98G [00:31<00:03, 175MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  94%|█████████▍| 9.43G/9.98G [00:31<00:03, 175MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  95%|█████████▍| 9.45G/9.98G [00:31<00:03, 169MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  95%|█████████▍| 9.47G/9.98G [00:31<00:02, 170MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  95%|█████████▌| 9.49G/9.98G [00:31<00:02, 167MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  95%|█████████▌| 9.51G/9.98G [00:31<00:02, 171MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  96%|█████████▌| 9.53G/9.98G [00:31<00:02, 164MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  96%|█████████▌| 9.55G/9.98G [00:32<00:02, 165MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  96%|█████████▌| 9.57G/9.98G [00:32<00:02, 169MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  96%|█████████▌| 9.59G/9.98G [00:32<00:02, 166MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  96%|█████████▋| 9.63G/9.98G [00:32<00:02, 171MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 9.65G/9.98G [00:32<00:01, 172MB/s]\n",
      "#033[A\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 9.67G/9.98G [00:32<00:01, 173MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 9.69G/9.98G [00:32<00:01, 173MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 9.71G/9.98G [00:32<00:01, 174MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 9.73G/9.98G [00:33<00:01, 174MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 9.75G/9.98G [00:33<00:01, 163MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 9.77G/9.98G [00:33<00:01, 170MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 9.79G/9.98G [00:33<00:01, 171MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 9.81G/9.98G [00:33<00:00, 172MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  99%|█████████▊| 9.84G/9.98G [00:33<00:01, 117MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  99%|█████████▉| 9.89G/9.98G [00:34<00:00, 193MB/s]#033[A\n",
      "model-00001-of-00002.safetensors:  99%|█████████▉| 9.92G/9.98G [00:34<00:00, 212MB/s]#033[A\n",
      "model-00001-of-00002.safetensors: 100%|█████████▉| 9.95G/9.98G [00:34<00:00, 200MB/s]#033[A\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 9.98G/9.98G [00:34<00:00, 176MB/s]#033[A\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 9.98G/9.98G [00:34<00:00, 289MB/s]\n",
      "Downloading shards:  50%|█████     | 1/2 [00:34<00:34, 34.58s/it]\n",
      "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]#033[A\n",
      "model-00002-of-00002.safetensors:   1%|          | 41.9M/3.50G [00:00<00:11, 306MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:   2%|▏         | 73.4M/3.50G [00:00<00:15, 223MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:   3%|▎         | 105M/3.50G [00:00<00:17, 198MB/s] #033[A\n",
      "model-00002-of-00002.safetensors:   4%|▎         | 126M/3.50G [00:00<00:17, 192MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:   4%|▍         | 147M/3.50G [00:00<00:17, 187MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:   5%|▍         | 168M/3.50G [00:00<00:18, 182MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:   5%|▌         | 189M/3.50G [00:00<00:18, 180MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:   6%|▌         | 210M/3.50G [00:01<00:18, 178MB/s]\n",
      "#033[A\n",
      "model-00002-of-00002.safetensors:   7%|▋         | 241M/3.50G [00:01<00:16, 194MB/s]\n",
      "#033[A\n",
      "model-00002-of-00002.safetensors:   7%|▋         | 262M/3.50G [00:01<00:16, 197MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:   9%|▊         | 304M/3.50G [00:01<00:13, 233MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  10%|▉         | 336M/3.50G [00:01<00:13, 241MB/s]\n",
      "#033[A\n",
      "model-00002-of-00002.safetensors:  10%|█         | 367M/3.50G [00:01<00:12, 247MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  11%|█▏        | 398M/3.50G [00:01<00:12, 252MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  12%|█▏        | 430M/3.50G [00:01<00:12, 253MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  13%|█▎        | 461M/3.50G [00:02<00:11, 253MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  14%|█▍        | 493M/3.50G [00:02<00:11, 252MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  15%|█▍        | 524M/3.50G [00:02<00:11, 266MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  16%|█▌        | 556M/3.50G [00:02<00:11, 263MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  17%|█▋        | 587M/3.50G [00:02<00:11, 264MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  18%|█▊        | 619M/3.50G [00:02<00:10, 264MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  19%|█▊        | 650M/3.50G [00:02<00:10, 262MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  19%|█▉        | 682M/3.50G [00:02<00:11, 254MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  20%|██        | 713M/3.50G [00:03<00:10, 261MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  21%|██▏       | 744M/3.50G [00:03<00:10, 263MB/s]\n",
      "#033[A\n",
      "model-00002-of-00002.safetensors:  22%|██▏       | 776M/3.50G [00:03<00:11, 242MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  23%|██▎       | 807M/3.50G [00:03<00:11, 225MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  24%|██▍       | 839M/3.50G [00:03<00:13, 195MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  25%|██▍       | 860M/3.50G [00:03<00:13, 192MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  25%|██▌       | 881M/3.50G [00:03<00:13, 188MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  26%|██▌       | 902M/3.50G [00:04<00:13, 193MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  26%|██▋       | 923M/3.50G [00:04<00:13, 192MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  27%|██▋       | 944M/3.50G [00:04<00:14, 182MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  28%|██▊       | 965M/3.50G [00:04<00:14, 176MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  28%|██▊       | 986M/3.50G [00:04<00:13, 182MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  29%|██▉       | 1.01G/3.50G [00:04<00:13, 185MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  29%|██▉       | 1.03G/3.50G [00:04<00:13, 181MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  30%|██▉       | 1.05G/3.50G [00:04<00:13, 185MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  31%|███       | 1.07G/3.50G [00:04<00:13, 185MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  31%|███       | 1.09G/3.50G [00:05<00:13, 180MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  32%|███▏      | 1.11G/3.50G [00:05<00:13, 181MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  32%|███▏      | 1.13G/3.50G [00:05<00:13, 174MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  33%|███▎      | 1.15G/3.50G [00:05<00:13, 177MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  34%|███▎      | 1.17G/3.50G [00:05<00:13, 176MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  34%|███▍      | 1.20G/3.50G [00:05<00:13, 173MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  35%|███▍      | 1.22G/3.50G [00:05<00:13, 175MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  35%|███▌      | 1.24G/3.50G [00:05<00:12, 176MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  36%|███▌      | 1.26G/3.50G [00:06<00:12, 173MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  37%|███▋      | 1.28G/3.50G [00:06<00:13, 171MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  37%|███▋      | 1.30G/3.50G [00:06<00:12, 178MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  38%|███▊      | 1.32G/3.50G [00:06<00:12, 180MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  38%|███▊      | 1.34G/3.50G [00:06<00:12, 170MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  39%|███▉      | 1.36G/3.50G [00:06<00:13, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  40%|███▉      | 1.38G/3.50G [00:06<00:12, 167MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  40%|████      | 1.41G/3.50G [00:06<00:12, 171MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  41%|████      | 1.43G/3.50G [00:07<00:12, 169MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  42%|████▏     | 1.46G/3.50G [00:07<00:12, 170MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  42%|████▏     | 1.48G/3.50G [00:07<00:11, 174MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  43%|████▎     | 1.50G/3.50G [00:07<00:11, 170MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  43%|████▎     | 1.52G/3.50G [00:07<00:11, 168MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  44%|████▍     | 1.54G/3.50G [00:07<00:11, 176MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  45%|████▍     | 1.56G/3.50G [00:07<00:11, 171MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  45%|████▌     | 1.58G/3.50G [00:07<00:11, 170MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  46%|████▌     | 1.60G/3.50G [00:08<00:11, 168MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  46%|████▋     | 1.63G/3.50G [00:08<00:11, 169MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  47%|████▋     | 1.65G/3.50G [00:08<00:10, 173MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  48%|████▊     | 1.67G/3.50G [00:08<00:10, 168MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  48%|████▊     | 1.69G/3.50G [00:08<00:10, 167MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  49%|████▉     | 1.71G/3.50G [00:08<00:10, 165MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  49%|████▉     | 1.73G/3.50G [00:08<00:10, 173MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  50%|█████     | 1.75G/3.50G [00:08<00:10, 167MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  51%|█████     | 1.77G/3.50G [00:09<00:10, 167MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  51%|█████     | 1.79G/3.50G [00:09<00:10, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  52%|█████▏    | 1.81G/3.50G [00:09<00:10, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  52%|█████▏    | 1.84G/3.50G [00:09<00:13, 121MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  54%|█████▍    | 1.90G/3.50G [00:09<00:07, 202MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  55%|█████▌    | 1.93G/3.50G [00:09<00:08, 177MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  56%|█████▌    | 1.95G/3.50G [00:10<00:09, 168MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  56%|█████▋    | 1.97G/3.50G [00:10<00:09, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  57%|█████▋    | 1.99G/3.50G [00:10<00:08, 170MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  58%|█████▊    | 2.01G/3.50G [00:10<00:08, 169MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  58%|█████▊    | 2.03G/3.50G [00:10<00:08, 168MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  59%|█████▊    | 2.06G/3.50G [00:10<00:08, 169MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  59%|█████▉    | 2.08G/3.50G [00:10<00:08, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  60%|█████▉    | 2.10G/3.50G [00:11<00:08, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  61%|██████    | 2.12G/3.50G [00:11<00:08, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  61%|██████    | 2.14G/3.50G [00:11<00:08, 169MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  62%|██████▏   | 2.16G/3.50G [00:11<00:07, 172MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  62%|██████▏   | 2.18G/3.50G [00:11<00:08, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  63%|██████▎   | 2.20G/3.50G [00:11<00:07, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  64%|██████▎   | 2.22G/3.50G [00:11<00:07, 163MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  64%|██████▍   | 2.24G/3.50G [00:11<00:07, 167MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  65%|██████▍   | 2.26G/3.50G [00:12<00:07, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  65%|██████▌   | 2.29G/3.50G [00:12<00:07, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  66%|██████▌   | 2.31G/3.50G [00:12<00:07, 165MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  67%|██████▋   | 2.33G/3.50G [00:12<00:07, 159MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  67%|██████▋   | 2.35G/3.50G [00:12<00:06, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  68%|██████▊   | 2.37G/3.50G [00:12<00:06, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  68%|██████▊   | 2.39G/3.50G [00:12<00:06, 161MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  69%|██████▉   | 2.41G/3.50G [00:12<00:06, 163MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  69%|██████▉   | 2.43G/3.50G [00:13<00:06, 167MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  70%|███████   | 2.45G/3.50G [00:13<00:06, 163MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  71%|███████   | 2.47G/3.50G [00:13<00:06, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  71%|███████▏  | 2.50G/3.50G [00:13<00:06, 161MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  72%|███████▏  | 2.52G/3.50G [00:13<00:05, 168MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  72%|███████▏  | 2.54G/3.50G [00:13<00:05, 161MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  73%|███████▎  | 2.56G/3.50G [00:13<00:05, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  74%|███████▎  | 2.58G/3.50G [00:13<00:05, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  74%|███████▍  | 2.60G/3.50G [00:14<00:05, 163MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  75%|███████▍  | 2.62G/3.50G [00:14<00:05, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  75%|███████▌  | 2.64G/3.50G [00:14<00:05, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  76%|███████▌  | 2.66G/3.50G [00:14<00:05, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  77%|███████▋  | 2.68G/3.50G [00:14<00:05, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  77%|███████▋  | 2.71G/3.50G [00:14<00:04, 164MB/s]\n",
      "#033[A\n",
      "model-00002-of-00002.safetensors:  78%|███████▊  | 2.73G/3.50G [00:14<00:04, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  78%|███████▊  | 2.75G/3.50G [00:14<00:04, 163MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  79%|███████▉  | 2.77G/3.50G [00:15<00:04, 158MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  80%|███████▉  | 2.79G/3.50G [00:15<00:04, 168MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  80%|████████  | 2.81G/3.50G [00:15<00:04, 165MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  81%|████████  | 2.83G/3.50G [00:15<00:04, 160MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  81%|████████▏ | 2.85G/3.50G [00:15<00:03, 165MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  82%|████████▏ | 2.87G/3.50G [00:15<00:03, 159MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  83%|████████▎ | 2.89G/3.50G [00:15<00:03, 170MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  83%|████████▎ | 2.92G/3.50G [00:16<00:03, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  84%|████████▍ | 2.94G/3.50G [00:16<00:03, 166MB/s]\n",
      "#033[A\n",
      "model-00002-of-00002.safetensors:  84%|████████▍ | 2.96G/3.50G [00:16<00:03, 160MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  85%|████████▌ | 2.99G/3.50G [00:16<00:03, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  86%|████████▌ | 3.01G/3.50G [00:16<00:02, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  87%|████████▋ | 3.03G/3.50G [00:16<00:02, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  87%|████████▋ | 3.05G/3.50G [00:16<00:02, 161MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  88%|████████▊ | 3.07G/3.50G [00:16<00:02, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  88%|████████▊ | 3.09G/3.50G [00:17<00:02, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  89%|████████▉ | 3.11G/3.50G [00:17<00:02, 160MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  90%|████████▉ | 3.14G/3.50G [00:17<00:02, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  90%|█████████ | 3.16G/3.50G [00:17<00:02, 160MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  91%|█████████ | 3.18G/3.50G [00:17<00:01, 163MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  91%|█████████▏| 3.20G/3.50G [00:17<00:01, 160MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  92%|█████████▏| 3.22G/3.50G [00:17<00:01, 159MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  93%|█████████▎| 3.24G/3.50G [00:18<00:01, 166MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  93%|█████████▎| 3.26G/3.50G [00:18<00:01, 161MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  94%|█████████▍| 3.28G/3.50G [00:18<00:01, 161MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  94%|█████████▍| 3.30G/3.50G [00:18<00:01, 163MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  95%|█████████▍| 3.32G/3.50G [00:18<00:01, 161MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  96%|█████████▌| 3.34G/3.50G [00:18<00:00, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  96%|█████████▌| 3.37G/3.50G [00:18<00:00, 165MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  97%|█████████▋| 3.39G/3.50G [00:18<00:00, 160MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  97%|█████████▋| 3.41G/3.50G [00:19<00:00, 161MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  98%|█████████▊| 3.43G/3.50G [00:19<00:00, 173MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  99%|█████████▊| 3.45G/3.50G [00:19<00:00, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors:  99%|█████████▉| 3.47G/3.50G [00:19<00:00, 164MB/s]#033[A\n",
      "model-00002-of-00002.safetensors: 100%|█████████▉| 3.49G/3.50G [00:19<00:00, 162MB/s]#033[A\n",
      "model-00002-of-00002.safetensors: 100%|██████████| 3.50G/3.50G [00:19<00:00, 177MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [00:54<00:00, 25.91s/it]\n",
      "Downloading shards: 100%|██████████| 2/2 [00:54<00:00, 27.21s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.13s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.43s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.13s/it]\n",
      "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]\n",
      "generation_config.json: 100%|██████████| 116/116 [00:00<00:00, 1.33MB/s]\n",
      "tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]\n",
      "tokenizer_config.json: 100%|██████████| 749/749 [00:00<00:00, 7.87MB/s]\n",
      "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]\n",
      "tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 481MB/s]\n",
      "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]\n",
      "tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 32.3MB/s]\n",
      "special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]\n",
      "special_tokens_map.json: 100%|██████████| 411/411 [00:00<00:00, 4.84MB/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "No chat template is defined for this tokenizer - using the default template for the CodeLlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "No chat template is defined for this tokenizer - using the default template for the CodeLlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "Generating train split: 1 examples [00:01,  1.86s/ examples]\n",
      "Generating train split: 245 examples [00:01, 172.86 examples/s]\n",
      "Generating train split: 416 examples [00:02, 197.78 examples/s]\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "0%|          | 0/312 [00:00<?, ?it/s]\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
      "0%|          | 1/312 [00:18<1:37:18, 18.77s/it]\n",
      "1%|          | 2/312 [00:36<1:35:14, 18.43s/it]\n",
      "1%|          | 3/312 [00:55<1:34:22, 18.33s/it]\n",
      "1%|▏         | 4/312 [01:13<1:33:48, 18.28s/it]\n",
      "2%|▏         | 5/312 [01:31<1:33:22, 18.25s/it]\n",
      "2%|▏         | 6/312 [01:49<1:32:58, 18.23s/it]\n",
      "2%|▏         | 7/312 [02:07<1:32:37, 18.22s/it]\n",
      "3%|▎         | 8/312 [02:26<1:32:17, 18.21s/it]\n",
      "3%|▎         | 9/312 [02:44<1:31:57, 18.21s/it]\n",
      "3%|▎         | 10/312 [03:02<1:31:38, 18.21s/it]\n",
      "{'loss': 0.9418, 'grad_norm': 0.07568359375, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
      "3%|▎         | 10/312 [03:02<1:31:38, 18.21s/it]\n",
      "4%|▎         | 11/312 [03:20<1:31:19, 18.20s/it]\n",
      "4%|▍         | 12/312 [03:38<1:31:00, 18.20s/it]\n",
      "4%|▍         | 13/312 [03:57<1:30:41, 18.20s/it]\n",
      "4%|▍         | 14/312 [04:15<1:30:23, 18.20s/it]\n",
      "5%|▍         | 15/312 [04:33<1:30:05, 18.20s/it]\n",
      "5%|▌         | 16/312 [04:51<1:29:46, 18.20s/it]\n",
      "5%|▌         | 17/312 [05:09<1:29:28, 18.20s/it]\n",
      "6%|▌         | 18/312 [05:28<1:29:10, 18.20s/it]\n",
      "6%|▌         | 19/312 [05:46<1:28:51, 18.20s/it]\n",
      "6%|▋         | 20/312 [06:04<1:28:33, 18.20s/it]\n",
      "{'loss': 0.7638, 'grad_norm': 0.0634765625, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
      "6%|▋         | 20/312 [06:04<1:28:33, 18.20s/it]\n",
      "7%|▋         | 21/312 [06:22<1:28:15, 18.20s/it]\n",
      "7%|▋         | 22/312 [06:40<1:27:57, 18.20s/it]\n",
      "7%|▋         | 23/312 [06:59<1:27:38, 18.20s/it]\n",
      "8%|▊         | 24/312 [07:17<1:27:20, 18.20s/it]\n",
      "8%|▊         | 25/312 [07:35<1:27:02, 18.20s/it]\n",
      "8%|▊         | 26/312 [07:53<1:26:44, 18.20s/it]\n",
      "9%|▊         | 27/312 [08:11<1:26:26, 18.20s/it]\n",
      "9%|▉         | 28/312 [08:30<1:26:07, 18.20s/it]\n",
      "9%|▉         | 29/312 [08:48<1:25:49, 18.20s/it]\n",
      "10%|▉         | 30/312 [09:06<1:25:31, 18.20s/it]\n",
      "{'loss': 0.6835, 'grad_norm': 0.0810546875, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
      "10%|▉         | 30/312 [09:06<1:25:31, 18.20s/it]\n",
      "10%|▉         | 31/312 [09:24<1:25:13, 18.20s/it]\n",
      "10%|█         | 32/312 [09:42<1:24:55, 18.20s/it]\n",
      "11%|█         | 33/312 [10:01<1:24:37, 18.20s/it]\n",
      "11%|█         | 34/312 [10:19<1:24:18, 18.20s/it]\n",
      "11%|█         | 35/312 [10:37<1:24:00, 18.20s/it]\n",
      "12%|█▏        | 36/312 [10:55<1:23:42, 18.20s/it]\n",
      "12%|█▏        | 37/312 [11:13<1:23:23, 18.20s/it]\n",
      "12%|█▏        | 38/312 [11:32<1:23:11, 18.22s/it]\n",
      "12%|█▎        | 39/312 [11:50<1:22:51, 18.21s/it]\n",
      "13%|█▎        | 40/312 [12:08<1:22:31, 18.21s/it]\n",
      "{'loss': 0.6212, 'grad_norm': 0.08984375, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
      "13%|█▎        | 40/312 [12:08<1:22:31, 18.21s/it]\n",
      "13%|█▎        | 41/312 [12:26<1:22:13, 18.20s/it]\n",
      "13%|█▎        | 42/312 [12:44<1:21:54, 18.20s/it]\n",
      "14%|█▍        | 43/312 [13:03<1:21:35, 18.20s/it]\n",
      "14%|█▍        | 44/312 [13:21<1:21:17, 18.20s/it]\n",
      "14%|█▍        | 45/312 [13:39<1:20:58, 18.20s/it]\n",
      "15%|█▍        | 46/312 [13:57<1:20:40, 18.20s/it]\n",
      "15%|█▌        | 47/312 [14:15<1:20:22, 18.20s/it]\n",
      "15%|█▌        | 48/312 [14:34<1:20:03, 18.20s/it]\n",
      "16%|█▌        | 49/312 [14:52<1:19:45, 18.20s/it]\n",
      "16%|█▌        | 50/312 [15:10<1:19:27, 18.20s/it]\n",
      "{'loss': 0.5625, 'grad_norm': 0.1279296875, 'learning_rate': 0.0002, 'epoch': 0.48}\n",
      "16%|█▌        | 50/312 [15:10<1:19:27, 18.20s/it]\n",
      "16%|█▋        | 51/312 [15:28<1:19:09, 18.20s/it]\n",
      "17%|█▋        | 52/312 [15:46<1:18:51, 18.20s/it]\n",
      "17%|█▋        | 53/312 [16:05<1:18:32, 18.20s/it]\n",
      "17%|█▋        | 54/312 [16:23<1:18:14, 18.20s/it]\n",
      "18%|█▊        | 55/312 [16:41<1:17:56, 18.20s/it]\n",
      "18%|█▊        | 56/312 [16:59<1:17:38, 18.20s/it]\n",
      "18%|█▊        | 57/312 [17:17<1:17:20, 18.20s/it]\n",
      "19%|█▊        | 58/312 [17:36<1:17:01, 18.20s/it]\n",
      "19%|█▉        | 59/312 [17:54<1:16:43, 18.20s/it]\n",
      "19%|█▉        | 60/312 [18:12<1:16:25, 18.20s/it]\n",
      "{'loss': 0.5458, 'grad_norm': 0.05859375, 'learning_rate': 0.0002, 'epoch': 0.58}\n",
      "19%|█▉        | 60/312 [18:12<1:16:25, 18.20s/it]\n",
      "20%|█▉        | 61/312 [18:30<1:16:07, 18.20s/it]\n",
      "20%|█▉        | 62/312 [18:48<1:15:49, 18.20s/it]\n",
      "20%|██        | 63/312 [19:07<1:15:30, 18.20s/it]\n",
      "21%|██        | 64/312 [19:25<1:15:12, 18.20s/it]\n",
      "21%|██        | 65/312 [19:43<1:14:54, 18.20s/it]\n",
      "21%|██        | 66/312 [20:01<1:14:36, 18.20s/it]\n",
      "21%|██▏       | 67/312 [20:19<1:14:18, 18.20s/it]\n",
      "22%|██▏       | 68/312 [20:38<1:14:00, 18.20s/it]\n",
      "22%|██▏       | 69/312 [20:56<1:13:41, 18.20s/it]\n",
      "22%|██▏       | 70/312 [21:14<1:13:23, 18.20s/it]\n",
      "{'loss': 0.526, 'grad_norm': 0.061767578125, 'learning_rate': 0.0002, 'epoch': 0.67}\n",
      "22%|██▏       | 70/312 [21:14<1:13:23, 18.20s/it]\n",
      "23%|██▎       | 71/312 [21:32<1:13:05, 18.20s/it]\n",
      "23%|██▎       | 72/312 [21:50<1:12:47, 18.20s/it]\n",
      "23%|██▎       | 73/312 [22:09<1:12:28, 18.20s/it]\n",
      "24%|██▎       | 74/312 [22:27<1:12:10, 18.20s/it]\n",
      "24%|██▍       | 75/312 [22:45<1:11:52, 18.20s/it]\n",
      "24%|██▍       | 76/312 [23:03<1:11:34, 18.20s/it]\n",
      "25%|██▍       | 77/312 [23:21<1:11:15, 18.20s/it]\n",
      "25%|██▌       | 78/312 [23:39<1:10:57, 18.20s/it]\n",
      "25%|██▌       | 79/312 [23:58<1:10:39, 18.20s/it]\n",
      "26%|██▌       | 80/312 [24:16<1:10:21, 18.20s/it]\n",
      "{'loss': 0.5189, 'grad_norm': 0.06787109375, 'learning_rate': 0.0002, 'epoch': 0.77}\n",
      "26%|██▌       | 80/312 [24:16<1:10:21, 18.20s/it]\n",
      "26%|██▌       | 81/312 [24:34<1:10:03, 18.20s/it]\n",
      "26%|██▋       | 82/312 [24:52<1:09:45, 18.20s/it]\n",
      "27%|██▋       | 83/312 [25:10<1:09:27, 18.20s/it]\n",
      "27%|██▋       | 84/312 [25:29<1:09:08, 18.20s/it]\n",
      "27%|██▋       | 85/312 [25:47<1:08:50, 18.20s/it]\n",
      "28%|██▊       | 86/312 [26:05<1:08:32, 18.20s/it]\n",
      "28%|██▊       | 87/312 [26:23<1:08:14, 18.20s/it]\n",
      "28%|██▊       | 88/312 [26:41<1:07:55, 18.20s/it]\n",
      "29%|██▊       | 89/312 [27:00<1:07:37, 18.20s/it]\n",
      "29%|██▉       | 90/312 [27:18<1:07:19, 18.20s/it]\n",
      "{'loss': 0.5029, 'grad_norm': 0.06982421875, 'learning_rate': 0.0002, 'epoch': 0.87}\n",
      "29%|██▉       | 90/312 [27:18<1:07:19, 18.20s/it]\n",
      "29%|██▉       | 91/312 [27:36<1:07:01, 18.20s/it]\n",
      "29%|██▉       | 92/312 [27:54<1:06:43, 18.20s/it]\n",
      "30%|██▉       | 93/312 [28:12<1:06:25, 18.20s/it]\n",
      "30%|███       | 94/312 [28:31<1:06:06, 18.20s/it]\n",
      "30%|███       | 95/312 [28:49<1:05:48, 18.20s/it]\n",
      "31%|███       | 96/312 [29:07<1:05:30, 18.20s/it]\n",
      "31%|███       | 97/312 [29:25<1:05:12, 18.20s/it]\n",
      "31%|███▏      | 98/312 [29:43<1:04:54, 18.20s/it]\n",
      "32%|███▏      | 99/312 [30:02<1:04:35, 18.20s/it]\n",
      "32%|███▏      | 100/312 [30:20<1:04:17, 18.20s/it]\n",
      "{'loss': 0.5035, 'grad_norm': 0.0703125, 'learning_rate': 0.0002, 'epoch': 0.96}\n",
      "32%|███▏      | 100/312 [30:20<1:04:17, 18.20s/it]\n",
      "32%|███▏      | 101/312 [30:38<1:04:04, 18.22s/it]\n",
      "33%|███▎      | 102/312 [30:56<1:03:44, 18.21s/it]\n",
      "33%|███▎      | 103/312 [31:14<1:03:25, 18.21s/it]\n",
      "33%|███▎      | 104/312 [31:33<1:03:06, 18.20s/it]\n",
      "34%|███▎      | 105/312 [31:51<1:03:16, 18.34s/it]\n",
      "34%|███▍      | 106/312 [32:10<1:02:49, 18.30s/it]\n",
      "34%|███▍      | 107/312 [32:28<1:02:24, 18.27s/it]\n",
      "35%|███▍      | 108/312 [32:46<1:02:02, 18.25s/it]\n",
      "35%|███▍      | 109/312 [33:04<1:01:40, 18.23s/it]\n",
      "35%|███▌      | 110/312 [33:22<1:01:20, 18.22s/it]\n",
      "{'loss': 0.4836, 'grad_norm': 0.072265625, 'learning_rate': 0.0002, 'epoch': 1.06}\n",
      "35%|███▌      | 110/312 [33:22<1:01:20, 18.22s/it]\n",
      "36%|███▌      | 111/312 [33:41<1:01:01, 18.21s/it]\n",
      "36%|███▌      | 112/312 [33:59<1:00:41, 18.21s/it]\n",
      "36%|███▌      | 113/312 [34:17<1:00:22, 18.21s/it]\n",
      "37%|███▋      | 114/312 [34:35<1:00:04, 18.20s/it]\n",
      "37%|███▋      | 115/312 [34:53<59:45, 18.20s/it]\n",
      "37%|███▋      | 116/312 [35:12<59:27, 18.20s/it]\n",
      "38%|███▊      | 117/312 [35:30<59:08, 18.20s/it]\n",
      "38%|███▊      | 118/312 [35:48<58:50, 18.20s/it]\n",
      "38%|███▊      | 119/312 [36:06<58:32, 18.20s/it]\n",
      "38%|███▊      | 120/312 [36:24<58:14, 18.20s/it]\n",
      "{'loss': 0.4738, 'grad_norm': 0.07763671875, 'learning_rate': 0.0002, 'epoch': 1.15}\n",
      "38%|███▊      | 120/312 [36:24<58:14, 18.20s/it]\n",
      "39%|███▉      | 121/312 [36:43<57:55, 18.20s/it]\n",
      "39%|███▉      | 122/312 [37:01<57:37, 18.20s/it]\n",
      "39%|███▉      | 123/312 [37:19<57:19, 18.20s/it]\n",
      "40%|███▉      | 124/312 [37:37<57:01, 18.20s/it]\n",
      "40%|████      | 125/312 [37:55<56:42, 18.20s/it]\n",
      "40%|████      | 126/312 [38:13<56:24, 18.20s/it]\n",
      "41%|████      | 127/312 [38:32<56:06, 18.20s/it]\n",
      "41%|████      | 128/312 [38:50<55:48, 18.20s/it]\n",
      "41%|████▏     | 129/312 [39:08<55:30, 18.20s/it]\n",
      "42%|████▏     | 130/312 [39:26<55:11, 18.20s/it]\n",
      "{'loss': 0.4665, 'grad_norm': 0.0791015625, 'learning_rate': 0.0002, 'epoch': 1.25}\n",
      "42%|████▏     | 130/312 [39:26<55:11, 18.20s/it]\n",
      "42%|████▏     | 131/312 [39:44<54:53, 18.20s/it]\n",
      "42%|████▏     | 132/312 [40:03<54:35, 18.20s/it]\n",
      "43%|████▎     | 133/312 [40:21<54:17, 18.20s/it]\n",
      "43%|████▎     | 134/312 [40:39<53:59, 18.20s/it]\n",
      "43%|████▎     | 135/312 [40:57<53:40, 18.20s/it]\n",
      "44%|████▎     | 136/312 [41:15<53:22, 18.20s/it]\n",
      "44%|████▍     | 137/312 [41:34<53:04, 18.20s/it]\n",
      "44%|████▍     | 138/312 [41:52<52:46, 18.20s/it]\n",
      "45%|████▍     | 139/312 [42:10<52:28, 18.20s/it]\n",
      "45%|████▍     | 140/312 [42:28<52:09, 18.20s/it]\n",
      "{'loss': 0.4693, 'grad_norm': 0.07861328125, 'learning_rate': 0.0002, 'epoch': 1.35}\n",
      "45%|████▍     | 140/312 [42:28<52:09, 18.20s/it]\n",
      "45%|████▌     | 141/312 [42:46<51:51, 18.20s/it]\n",
      "46%|████▌     | 142/312 [43:05<51:33, 18.20s/it]\n",
      "46%|████▌     | 143/312 [43:23<51:15, 18.20s/it]\n",
      "46%|████▌     | 144/312 [43:41<50:57, 18.20s/it]\n",
      "46%|████▋     | 145/312 [43:59<50:39, 18.20s/it]\n",
      "47%|████▋     | 146/312 [44:17<50:20, 18.20s/it]\n",
      "47%|████▋     | 147/312 [44:36<50:02, 18.20s/it]\n",
      "47%|████▋     | 148/312 [44:54<49:44, 18.20s/it]\n",
      "48%|████▊     | 149/312 [45:12<49:26, 18.20s/it]\n",
      "48%|████▊     | 150/312 [45:30<49:07, 18.20s/it]\n",
      "{'loss': 0.4592, 'grad_norm': 0.08203125, 'learning_rate': 0.0002, 'epoch': 1.44}\n",
      "48%|████▊     | 150/312 [45:30<49:07, 18.20s/it]\n",
      "48%|████▊     | 151/312 [45:48<48:49, 18.20s/it]\n",
      "49%|████▊     | 152/312 [46:07<48:31, 18.20s/it]\n",
      "49%|████▉     | 153/312 [46:25<48:13, 18.20s/it]\n",
      "49%|████▉     | 154/312 [46:43<47:58, 18.22s/it]\n",
      "50%|████▉     | 155/312 [47:01<47:39, 18.21s/it]\n",
      "50%|█████     | 156/312 [47:19<47:20, 18.21s/it]\n",
      "50%|█████     | 157/312 [47:38<47:01, 18.20s/it]\n",
      "51%|█████     | 158/312 [47:56<46:43, 18.20s/it]\n",
      "51%|█████     | 159/312 [48:14<46:24, 18.20s/it]\n",
      "51%|█████▏    | 160/312 [48:32<46:06, 18.20s/it]\n",
      "{'loss': 0.4591, 'grad_norm': 0.07568359375, 'learning_rate': 0.0002, 'epoch': 1.54}\n",
      "51%|█████▏    | 160/312 [48:32<46:06, 18.20s/it]\n",
      "52%|█████▏    | 161/312 [48:50<45:48, 18.20s/it]\n",
      "52%|█████▏    | 162/312 [49:09<45:29, 18.20s/it]\n",
      "52%|█████▏    | 163/312 [49:27<45:11, 18.20s/it]\n",
      "53%|█████▎    | 164/312 [49:45<44:53, 18.20s/it]\n",
      "53%|█████▎    | 165/312 [50:03<44:34, 18.20s/it]\n",
      "53%|█████▎    | 166/312 [50:21<44:16, 18.20s/it]\n",
      "54%|█████▎    | 167/312 [50:40<43:58, 18.20s/it]\n",
      "54%|█████▍    | 168/312 [50:58<43:40, 18.20s/it]\n",
      "54%|█████▍    | 169/312 [51:16<43:22, 18.20s/it]\n",
      "54%|█████▍    | 170/312 [51:34<43:03, 18.20s/it]\n",
      "{'loss': 0.4585, 'grad_norm': 0.083984375, 'learning_rate': 0.0002, 'epoch': 1.63}\n",
      "54%|█████▍    | 170/312 [51:34<43:03, 18.20s/it]\n",
      "55%|█████▍    | 171/312 [51:52<42:45, 18.20s/it]\n",
      "55%|█████▌    | 172/312 [52:11<42:27, 18.20s/it]\n",
      "55%|█████▌    | 173/312 [52:29<42:09, 18.20s/it]\n",
      "56%|█████▌    | 174/312 [52:47<41:51, 18.20s/it]\n",
      "56%|█████▌    | 175/312 [53:05<41:32, 18.20s/it]\n",
      "56%|█████▋    | 176/312 [53:23<41:14, 18.20s/it]\n",
      "57%|█████▋    | 177/312 [53:42<40:56, 18.20s/it]\n",
      "57%|█████▋    | 178/312 [54:00<40:38, 18.20s/it]\n",
      "57%|█████▋    | 179/312 [54:18<40:20, 18.20s/it]\n",
      "58%|█████▊    | 180/312 [54:36<40:01, 18.20s/it]\n",
      "{'loss': 0.4561, 'grad_norm': 0.08203125, 'learning_rate': 0.0002, 'epoch': 1.73}\n",
      "58%|█████▊    | 180/312 [54:36<40:01, 18.20s/it]\n",
      "58%|█████▊    | 181/312 [54:54<39:43, 18.20s/it]\n",
      "58%|█████▊    | 182/312 [55:13<39:25, 18.20s/it]\n",
      "59%|█████▊    | 183/312 [55:31<39:07, 18.20s/it]\n",
      "59%|█████▉    | 184/312 [55:49<38:49, 18.20s/it]\n",
      "59%|█████▉    | 185/312 [56:07<38:31, 18.20s/it]\n",
      "60%|█████▉    | 186/312 [56:25<38:12, 18.20s/it]\n",
      "60%|█████▉    | 187/312 [56:44<37:54, 18.20s/it]\n",
      "60%|██████    | 188/312 [57:02<37:36, 18.20s/it]\n",
      "61%|██████    | 189/312 [57:20<37:18, 18.20s/it]\n",
      "61%|██████    | 190/312 [57:38<36:59, 18.20s/it]\n",
      "{'loss': 0.4543, 'grad_norm': 0.09033203125, 'learning_rate': 0.0002, 'epoch': 1.83}\n",
      "61%|██████    | 190/312 [57:38<36:59, 18.20s/it]\n",
      "61%|██████    | 191/312 [57:56<36:41, 18.20s/it]\n",
      "62%|██████▏   | 192/312 [58:15<36:23, 18.20s/it]\n",
      "62%|██████▏   | 193/312 [58:33<36:05, 18.20s/it]\n",
      "62%|██████▏   | 194/312 [58:51<35:47, 18.20s/it]\n",
      "62%|██████▎   | 195/312 [59:09<35:29, 18.20s/it]\n",
      "63%|██████▎   | 196/312 [59:27<35:11, 18.20s/it]\n",
      "63%|██████▎   | 197/312 [59:46<34:52, 18.20s/it]\n",
      "63%|██████▎   | 198/312 [1:00:04<34:34, 18.20s/it]\n",
      "64%|██████▍   | 199/312 [1:00:22<34:16, 18.20s/it]\n",
      "64%|██████▍   | 200/312 [1:00:40<33:58, 18.20s/it]\n",
      "{'loss': 0.45, 'grad_norm': 0.08984375, 'learning_rate': 0.0002, 'epoch': 1.92}\n",
      "64%|██████▍   | 200/312 [1:00:40<33:58, 18.20s/it]\n",
      "64%|██████▍   | 201/312 [1:00:58<33:39, 18.20s/it]\n",
      "65%|██████▍   | 202/312 [1:01:17<33:21, 18.20s/it]\n",
      "65%|██████▌   | 203/312 [1:01:35<33:03, 18.20s/it]\n",
      "65%|██████▌   | 204/312 [1:01:53<32:45, 18.20s/it]\n",
      "66%|██████▌   | 205/312 [1:02:11<32:27, 18.20s/it]\n",
      "66%|██████▌   | 206/312 [1:02:29<32:08, 18.20s/it]\n",
      "66%|██████▋   | 207/312 [1:02:48<31:50, 18.20s/it]\n",
      "67%|██████▋   | 208/312 [1:03:06<31:32, 18.20s/it]\n",
      "67%|██████▋   | 209/312 [1:03:24<31:28, 18.34s/it]\n",
      "67%|██████▋   | 210/312 [1:03:43<31:06, 18.30s/it]\n",
      "{'loss': 0.4493, 'grad_norm': 0.09130859375, 'learning_rate': 0.0002, 'epoch': 2.02}\n",
      "67%|██████▋   | 210/312 [1:03:43<31:06, 18.30s/it]\n",
      "68%|██████▊   | 211/312 [1:04:01<30:46, 18.29s/it]\n",
      "68%|██████▊   | 212/312 [1:04:19<30:25, 18.26s/it]\n",
      "68%|██████▊   | 213/312 [1:04:37<30:05, 18.24s/it]\n",
      "69%|██████▊   | 214/312 [1:04:55<29:46, 18.23s/it]\n",
      "69%|██████▉   | 215/312 [1:05:14<29:27, 18.22s/it]\n",
      "69%|██████▉   | 216/312 [1:05:32<29:08, 18.21s/it]\n",
      "70%|██████▉   | 217/312 [1:05:50<28:49, 18.21s/it]\n",
      "70%|██████▉   | 218/312 [1:06:08<28:31, 18.20s/it]\n",
      "70%|███████   | 219/312 [1:06:26<28:12, 18.20s/it]\n",
      "71%|███████   | 220/312 [1:06:45<27:54, 18.20s/it]\n",
      "{'loss': 0.4245, 'grad_norm': 0.09228515625, 'learning_rate': 0.0002, 'epoch': 2.12}\n",
      "71%|███████   | 220/312 [1:06:45<27:54, 18.20s/it]\n",
      "71%|███████   | 221/312 [1:07:03<27:36, 18.20s/it]\n",
      "71%|███████   | 222/312 [1:07:21<27:17, 18.20s/it]\n",
      "71%|███████▏  | 223/312 [1:07:39<26:59, 18.20s/it]\n",
      "72%|███████▏  | 224/312 [1:07:57<26:41, 18.20s/it]\n",
      "72%|███████▏  | 225/312 [1:08:16<26:23, 18.20s/it]\n",
      "72%|███████▏  | 226/312 [1:08:34<26:04, 18.20s/it]\n",
      "73%|███████▎  | 227/312 [1:08:52<25:46, 18.20s/it]\n",
      "73%|███████▎  | 228/312 [1:09:10<25:28, 18.20s/it]\n",
      "73%|███████▎  | 229/312 [1:09:28<25:10, 18.20s/it]\n",
      "74%|███████▎  | 230/312 [1:09:47<24:52, 18.20s/it]\n",
      "{'loss': 0.4221, 'grad_norm': 0.0986328125, 'learning_rate': 0.0002, 'epoch': 2.21}\n",
      "74%|███████▎  | 230/312 [1:09:47<24:52, 18.20s/it]\n",
      "74%|███████▍  | 231/312 [1:10:05<24:33, 18.20s/it]\n",
      "74%|███████▍  | 232/312 [1:10:23<24:15, 18.20s/it]\n",
      "75%|███████▍  | 233/312 [1:10:41<23:57, 18.20s/it]\n",
      "75%|███████▌  | 234/312 [1:10:59<23:39, 18.20s/it]\n",
      "75%|███████▌  | 235/312 [1:11:18<23:21, 18.20s/it]\n",
      "76%|███████▌  | 236/312 [1:11:36<23:02, 18.20s/it]\n",
      "76%|███████▌  | 237/312 [1:11:54<22:44, 18.20s/it]\n",
      "76%|███████▋  | 238/312 [1:12:12<22:26, 18.20s/it]\n",
      "77%|███████▋  | 239/312 [1:12:30<22:08, 18.20s/it]\n",
      "77%|███████▋  | 240/312 [1:12:49<21:50, 18.20s/it]\n",
      "{'loss': 0.4168, 'grad_norm': 0.0986328125, 'learning_rate': 0.0002, 'epoch': 2.31}\n",
      "77%|███████▋  | 240/312 [1:12:49<21:50, 18.20s/it]\n",
      "77%|███████▋  | 241/312 [1:13:07<21:32, 18.20s/it]\n",
      "78%|███████▊  | 242/312 [1:13:25<21:13, 18.20s/it]\n",
      "78%|███████▊  | 243/312 [1:13:43<20:55, 18.20s/it]\n",
      "78%|███████▊  | 244/312 [1:14:01<20:37, 18.20s/it]\n",
      "79%|███████▊  | 245/312 [1:14:20<20:19, 18.20s/it]\n",
      "79%|███████▉  | 246/312 [1:14:38<20:01, 18.20s/it]\n",
      "79%|███████▉  | 247/312 [1:14:56<19:42, 18.20s/it]\n",
      "79%|███████▉  | 248/312 [1:15:14<19:24, 18.20s/it]\n",
      "80%|███████▉  | 249/312 [1:15:32<19:06, 18.20s/it]\n",
      "80%|████████  | 250/312 [1:15:51<18:48, 18.20s/it]\n",
      "{'loss': 0.4241, 'grad_norm': 0.099609375, 'learning_rate': 0.0002, 'epoch': 2.4}\n",
      "80%|████████  | 250/312 [1:15:51<18:48, 18.20s/it]\n",
      "80%|████████  | 251/312 [1:16:09<18:30, 18.20s/it]\n",
      "81%|████████  | 252/312 [1:16:27<18:11, 18.20s/it]\n",
      "81%|████████  | 253/312 [1:16:45<17:53, 18.20s/it]\n",
      "81%|████████▏ | 254/312 [1:17:03<17:35, 18.20s/it]\n",
      "82%|████████▏ | 255/312 [1:17:22<17:17, 18.20s/it]\n",
      "82%|████████▏ | 256/312 [1:17:40<16:58, 18.20s/it]\n",
      "82%|████████▏ | 257/312 [1:17:58<16:40, 18.20s/it]\n",
      "83%|████████▎ | 258/312 [1:18:16<16:22, 18.20s/it]\n",
      "83%|████████▎ | 259/312 [1:18:34<16:04, 18.20s/it]\n",
      "83%|████████▎ | 260/312 [1:18:53<15:46, 18.20s/it]\n",
      "{'loss': 0.424, 'grad_norm': 0.1005859375, 'learning_rate': 0.0002, 'epoch': 2.5}\n",
      "83%|████████▎ | 260/312 [1:18:53<15:46, 18.20s/it]\n",
      "84%|████████▎ | 261/312 [1:19:11<15:27, 18.20s/it]\n",
      "84%|████████▍ | 262/312 [1:19:29<15:09, 18.20s/it]\n",
      "84%|████████▍ | 263/312 [1:19:47<14:51, 18.20s/it]\n",
      "85%|████████▍ | 264/312 [1:20:05<14:33, 18.20s/it]\n",
      "85%|████████▍ | 265/312 [1:20:24<14:15, 18.20s/it]\n",
      "85%|████████▌ | 266/312 [1:20:42<13:57, 18.20s/it]\n",
      "86%|████████▌ | 267/312 [1:21:00<13:38, 18.20s/it]\n",
      "86%|████████▌ | 268/312 [1:21:18<13:20, 18.20s/it]\n",
      "86%|████████▌ | 269/312 [1:21:36<13:02, 18.20s/it]\n",
      "87%|████████▋ | 270/312 [1:21:54<12:44, 18.20s/it]\n",
      "{'loss': 0.4198, 'grad_norm': 0.10009765625, 'learning_rate': 0.0002, 'epoch': 2.6}\n",
      "87%|████████▋ | 270/312 [1:21:55<12:44, 18.20s/it]\n",
      "87%|████████▋ | 271/312 [1:22:13<12:26, 18.20s/it]\n",
      "87%|████████▋ | 272/312 [1:22:31<12:07, 18.20s/it]\n",
      "88%|████████▊ | 273/312 [1:22:49<11:49, 18.20s/it]\n",
      "88%|████████▊ | 274/312 [1:23:07<11:32, 18.22s/it]\n",
      "88%|████████▊ | 275/312 [1:23:26<11:13, 18.21s/it]\n",
      "88%|████████▊ | 276/312 [1:23:44<10:55, 18.21s/it]\n",
      "89%|████████▉ | 277/312 [1:24:02<10:37, 18.20s/it]\n",
      "89%|████████▉ | 278/312 [1:24:20<10:18, 18.20s/it]\n",
      "89%|████████▉ | 279/312 [1:24:38<10:00, 18.20s/it]\n",
      "90%|████████▉ | 280/312 [1:24:57<09:42, 18.20s/it]\n",
      "{'loss': 0.4202, 'grad_norm': 0.10009765625, 'learning_rate': 0.0002, 'epoch': 2.69}\n",
      "90%|████████▉ | 280/312 [1:24:57<09:42, 18.20s/it]\n",
      "90%|█████████ | 281/312 [1:25:15<09:24, 18.20s/it]\n",
      "90%|█████████ | 282/312 [1:25:33<09:05, 18.20s/it]\n",
      "91%|█████████ | 283/312 [1:25:51<08:47, 18.20s/it]\n",
      "91%|█████████ | 284/312 [1:26:09<08:29, 18.20s/it]\n",
      "91%|█████████▏| 285/312 [1:26:28<08:11, 18.20s/it]\n",
      "92%|█████████▏| 286/312 [1:26:46<07:53, 18.20s/it]\n",
      "92%|█████████▏| 287/312 [1:27:04<07:34, 18.20s/it]\n",
      "92%|█████████▏| 288/312 [1:27:22<07:16, 18.20s/it]\n",
      "93%|█████████▎| 289/312 [1:27:40<06:58, 18.20s/it]\n",
      "93%|█████████▎| 290/312 [1:27:58<06:40, 18.20s/it]\n",
      "{'loss': 0.4223, 'grad_norm': 0.10302734375, 'learning_rate': 0.0002, 'epoch': 2.79}\n",
      "93%|█████████▎| 290/312 [1:27:58<06:40, 18.20s/it]\n",
      "93%|█████████▎| 291/312 [1:28:17<06:22, 18.20s/it]\n",
      "94%|█████████▎| 292/312 [1:28:35<06:03, 18.20s/it]\n",
      "94%|█████████▍| 293/312 [1:28:53<05:45, 18.20s/it]\n",
      "94%|█████████▍| 294/312 [1:29:11<05:27, 18.20s/it]\n",
      "95%|█████████▍| 295/312 [1:29:29<05:09, 18.20s/it]\n",
      "95%|█████████▍| 296/312 [1:29:48<04:51, 18.20s/it]\n",
      "95%|█████████▌| 297/312 [1:30:06<04:32, 18.20s/it]\n",
      "96%|█████████▌| 298/312 [1:30:24<04:14, 18.20s/it]\n",
      "96%|█████████▌| 299/312 [1:30:42<03:56, 18.20s/it]\n",
      "96%|█████████▌| 300/312 [1:31:00<03:38, 18.20s/it]\n",
      "{'loss': 0.4189, 'grad_norm': 0.10498046875, 'learning_rate': 0.0002, 'epoch': 2.88}\n",
      "96%|█████████▌| 300/312 [1:31:00<03:38, 18.20s/it]\n",
      "96%|█████████▋| 301/312 [1:31:19<03:20, 18.20s/it]\n",
      "97%|█████████▋| 302/312 [1:31:37<03:01, 18.20s/it]\n",
      "97%|█████████▋| 303/312 [1:31:55<02:43, 18.20s/it]\n",
      "97%|█████████▋| 304/312 [1:32:13<02:25, 18.20s/it]\n",
      "98%|█████████▊| 305/312 [1:32:31<02:07, 18.20s/it]\n",
      "98%|█████████▊| 306/312 [1:32:50<01:49, 18.20s/it]\n",
      "98%|█████████▊| 307/312 [1:33:08<01:30, 18.20s/it]\n",
      "99%|█████████▊| 308/312 [1:33:26<01:12, 18.20s/it]\n",
      "99%|█████████▉| 309/312 [1:33:44<00:54, 18.20s/it]\n",
      "99%|█████████▉| 310/312 [1:34:02<00:36, 18.20s/it]\n",
      "{'loss': 0.4132, 'grad_norm': 0.1044921875, 'learning_rate': 0.0002, 'epoch': 2.98}\n",
      "99%|█████████▉| 310/312 [1:34:02<00:36, 18.20s/it]\n",
      "100%|█████████▉| 311/312 [1:34:21<00:18, 18.20s/it]\n",
      "100%|██████████| 312/312 [1:34:39<00:00, 18.20s/it]\n",
      "{'train_runtime': 5679.7905, 'train_samples_per_second': 0.22, 'train_steps_per_second': 0.055, 'train_loss': 0.4980104019244512, 'epoch': 3.0}\n",
      "100%|██████████| 312/312 [1:34:39<00:00, 18.20s/it]\n",
      "100%|██████████| 312/312 [1:34:39<00:00, 18.20s/it]\n",
      "['adapter_config.json', 'runs', 'checkpoint-208', 'tokenizer_config.json', 'tokenizer.json', 'README.md', 'adapter_model.safetensors', 'checkpoint-312', 'checkpoint-104', 'tokenizer.model', 'special_tokens_map.json']\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:20<00:20, 20.81s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:31<00:00, 14.79s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:31<00:00, 15.70s/it]\n",
      "\n",
      "2024-03-08 09:49:15 Uploading - Uploading generated training model2024-03-08 09:49:10,847 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-03-08 09:49:10,848 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-03-08 09:49:10,848 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-03-08 09:49:56 Completed - Training job completed\n",
      "Training seconds: 6162\n",
      "Billable seconds: 6162\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-558105141721/codellama-7b-hf-text-to-sql-exp1-2024-03-08-08-05-53-957/output/model/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"].replace(\"s3://\", \"https://s3.console.aws.amazon.com/s3/buckets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py310\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.4.0-gpu-py310-cu121-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.4.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time add the s3 path here\n",
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2024-03-08-10-50-17-803\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2024-03-08-10-50-18-669\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2024-03-08-10-50-18-669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to give SageMaker the time to download the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3377004922844ae84ef9ab8594e01e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'For the attendance of 2 january 1999 with a home team of plymouth argyle what is the tie no. ?', 'role': 'user'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'SELECT tie_no FROM table_name_5 WHERE attendance = \"2 january 1999\" AND home_team = \"plymouth argyle\"'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")\n",
    "\n",
    "# Load the test dataset from s3\n",
    "S3Downloader.download(f\"{training_input_path}/test_dataset.json\", \".\")\n",
    "test_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\",split=\"train\")\n",
    "random_sample = test_dataset[345]\n",
    "\n",
    "def request(sample):\n",
    "    prompt = tokenizer.apply_chat_template(sample, tokenize=False, add_generation_prompt=True)\n",
    "    outputs = llm.predict({\n",
    "      \"inputs\": prompt,\n",
    "      \"parameters\": {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"do_sample\": False,\n",
    "        \"return_full_text\": False,\n",
    "        \"stop\": [\"<|im_end|>\"],\n",
    "      }\n",
    "    })\n",
    "    return {\"role\": \"assistant\", \"content\": outputs[0][\"generated_text\"].strip()}\n",
    "\n",
    "print(random_sample[\"messages\"][1])\n",
    "request(random_sample[\"messages\"][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Our model is working as expected. Now we can evaluate our model on 1000 samples from test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [16:10<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(sample):\n",
    "    predicted_answer = request(sample[\"messages\"][:2])\n",
    "    if predicted_answer[\"content\"] == sample[\"messages\"][2][\"content\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "success_rate = []\n",
    "number_of_eval_samples = 1000\n",
    "# iterate over eval dataset and predict\n",
    "for s in tqdm(test_dataset.shuffle().select(range(number_of_eval_samples))):\n",
    "    success_rate.append(evaluate(s))\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = sum(success_rate)/len(success_rate)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-tgi-inference-2024-03-08-10-50-17-803\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: huggingface-pytorch-tgi-inference-2024-03-08-10-50-18-669\n",
      "INFO:sagemaker:Deleting endpoint with name: huggingface-pytorch-tgi-inference-2024-03-08-10-50-18-669\n"
     ]
    }
   ],
   "source": [
    "llm.delete_model()\n",
    "llm.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
